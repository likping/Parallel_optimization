{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "from scipy.optimize import minimize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.69440347,  0.25208026, -0.7883007 , -0.73613   ],\n",
       "       [-0.1213868 ,  0.4582234 ,  0.66922635, -1.4988806 ],\n",
       "       [-0.61748666, -0.53340596,  0.7325721 , -0.09882516],\n",
       "       [-0.28886718, -0.2389829 ,  0.08443267,  0.8690153 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy \n",
    "a=numpy.random.randn(4,4)\n",
    "a=a.astype(numpy.float32)\n",
    "a_gpu=cuda.mem_alloc(a.nbytes)\n",
    "cuda.memcpy_htod(a_gpu,a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executing a Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.07021137 -0.86102444 -1.9212255   1.4122069 ]\n",
      " [-0.51889646  0.1509971   2.080334    0.03691731]\n",
      " [ 0.2966108   1.1588308  -0.5102222  -1.999049  ]\n",
      " [-1.1879143  -0.67628145 -0.716728    0.23844439]]\n",
      "[[-0.14042273 -1.7220489  -3.842451    2.8244138 ]\n",
      " [-1.0377929   0.3019942   4.160668    0.07383463]\n",
      " [ 0.5932216   2.3176615  -1.0204444  -3.998098  ]\n",
      " [-2.3758285  -1.3525629  -1.433456    0.47688878]]\n"
     ]
    }
   ],
   "source": [
    "mod=SourceModule(\"\"\"\n",
    "__global__ void doublify(float *a)\n",
    "{\n",
    "    int idx=threadIdx.x+threadIdx.y*4;\n",
    "    a[idx]*=2;\n",
    "}\n",
    "\"\"\")\n",
    "func=mod.get_function(\"doublify\")\n",
    "func(a_gpu,block=(4,4,1))\n",
    "a_doubled=numpy.empty_like(a)\n",
    "print(a)\n",
    "cuda.memcpy_dtoh(a_doubled,a_gpu)\n",
    "print(a_doubled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Abstracting Away the Complications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246 µs ± 847 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import pycuda.gpuarray as gpuarray\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import numpy\n",
    "a=numpy.random.randn(4,4).astype(numpy.float32)\n",
    "a_gpu=gpuarray.to_gpu(a)\n",
    "%timeit a_doubled=(2*a_gpu).get()\n",
    "# print(a_doubled)\n",
    "# print(a_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.96 µs ± 54.8 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit a*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed (with compilation) = 0.8302448028698564s\n",
      "Elapsed (after compilation) = 0.0001378101296722889s\n"
     ]
    }
   ],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "x = np.arange(100).reshape(10, 10)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def go_fast(a): # Function is compiled and runs in machine code\n",
    "    trace = 0.0\n",
    "    for i in range(a.shape[0]):\n",
    "        trace += np.tanh(a[i, i])\n",
    "    return a + trace\n",
    "\n",
    "# DO NOT REPORT THIS... COMPILATION TIME IS INCLUDED IN THE EXECUTION TIME!\n",
    "start = time.perf_counter()\n",
    "go_fast(x)\n",
    "end = time.perf_counter()\n",
    "print(\"Elapsed (with compilation) = {}s\".format((end - start)))\n",
    "\n",
    "# NOW THE FUNCTION IS COMPILED, RE-TIME IT EXECUTING FROM CACHE\n",
    "start = time.perf_counter()\n",
    "go_fast(x)\n",
    "end = time.perf_counter()\n",
    "print(\"Elapsed (after compilation) = {}s\".format((end - start)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('zyd_py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "039a26008ba899fb9263d79ea4fe0fbf1d6ceb2c2437134916b1db4a32b88c80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
